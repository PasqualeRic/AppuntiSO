Esercizio c.1: 

Un semaforo pesato è una struttura di sincronizzazione con due primitive P(w) e V(w) (oltre al costruttore
di inizializzazione). I parametri delle operazioni P e V sono i pesi dell'operazione. L'invariante dei semafori pesati
richiede che la somma dei pesi delle operazioni P completate sia sempre inferiore o uguale alla somma dei pesi delle
operazioni V completate più il valore di inizializzazione. Scrivere il monitor wsem in grado di implementare un semaforo
pesato fair: i processi che si bloccano a causa di una P che invaliderebbe l'invariante devono essere riattivati nell'ordine
in cui sono stati sospesi (FIFO)

Svolgimento:

Nota: 
anche i processi che potrebbero essere eseguiti devono bloccarsi e mantenere la fifoness? 
questa implementazione non tiene conto di questa cosa

monitor semaforopesato{
    
    int value;
    queue of integers q; 
    condition ok2p;

    entry void initialize(int w){
        value = w;
    }

    entry void P(int w){
        if (w > value){
            q.enqueue(w);
            ok2p.wait();
        }
        value -= w;
        if(!q.isEmpty() && value >= q.top()){
            wq = q.dequeue()
            ok2p.signal();
        }
    }

    entry void V(int w){
        value += w
        if(!q.isEmpty() && value >= q.top()){
            wq = q.dequeue()
            value -= wq;
            ok2p.signal();
        }
    }

}

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Esercizio c.2: 

Dato un servizio di message passing asincrono e senza fare uso di processi server:
a) implementare un servizio di message passing sincrono a ricezione multipla. Questo servizio prevede due funzioni
con la seguente interfaccia:
 ms_send(pid dest, msg_t msg)
 ms_recv(int n, pid *senders, msg_t *msgs)
L'operazione di ricezione deve attendere n messaggi, provenienti dai mittenti indicati nel vettore senders (ogni
elemento può essere ANY/*) e metterli ordinatamente nel vettore msgs (entrambi i vettori saranno stati
opportunamente allocati e dimensionati dal chiamante). I processi mittenti degli n messaggi devono rimanere in
attesa fino a che la ms_recv non può essere completata.
b) analizzare i casi di deadlock che possono accadere in base alla definizione del servizio di message passing sincrono
a ricezione multipla.

Svolgimento:

void ms_send(pid dest, msg_t msg){
    asend((realgetPid(),msg), dest);
    ack = arecv(dest);
}

void ms_recv(int n, pid *senders, msg_t *msgs){
    msg_t m;
    pid realSender;
    queue realsenders;
    for (int i=0; i<n; i++){
        (realSender, m) = arecv(senders[i])
        msgs.enqueue(m)
        realsenders.enqueue(realSender);
    }
    for(int i=0; i<n; i++){
        realSender = realsender.dequeue();
        asend(ack, realsender);
    }
}

Un possibile caso di deadlock è quello in cui un particolare mittente non invia il proprio messaggio e 
tutti gli alri restano in attesa all'infinito


////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Esercizio g.1:

Si consideri l'algoritmo del banchiere a tre valute. Si prenda in considerazione una situazione nella quale
tre processi p1, p2, p3 abbiano un massimo credito disponibile rispettivamente di (3, 2, 3), (3, 3, 2), (2, 3, 3), cioé per
esempio p1 può prendere in prestito 3 unità della prima e della terza valuta ma solo 2 della seconda. In un certo istante
p1 ha 2 unità della prima valute, p2 ha 2 unità della seconda, p3 ha 3 unità della terza e nessuna altra risorsa è stata
assegnata. Qual è il capitale iniziale minimo che consente allo stato di essere safe? (considerare tutti i casi possibili).

Svolgimento:

andiamo per casi:

numeroclienti N = 3
capitale iniziale IC = (x,y,z)

c1: (3, 2, 3)       p1: (2,0,0)     n1: (1,2,3) 
c2: (3, 3, 2)       p2: (0,2,0)     n2: (3,1,2)
c3: (2, 3, 3)       p3: (0,0,3)     n3: (2,3,0)

123: -> 3,2,3 -> 3,4,3 -> 3,4,6 
132: -> 3,2,3 -> 3,2,6 -> 3,5,6
213: -> 3,3,2 -> 5,3,3 -> 5,3,6
231: -> 3,3,2 -> 3,3,5 -> 5,3,5
312: -> 2,3,3 -> 4,3,3 -> 4,5,3
321: -> 2,3,3 -> 3,5,3 -> 5,5,3

se vogliamo essere sicuri che lo stato sia safe per qualunque ordine di esecuzione basta prendere il massimo valore per ogni valuta 
degli elementi elencati, ottenendo (5,5,6)


////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Esercizio g.2: 

Rispondere alle domande seguenti:

a) Ci sono spinlock (strutture di sincronizzazione simili al Test@Set) nel kernel Linux? Perché?

    Sicuramente sono presenti all'interno di kernel linux, questo perche l'utilizzo di strutture di sincronizzazione è fondamentale 
    per la corretta esecuzione dei programmi. Ovviamente però ogni sistema operativo implementa in modo personale sia le strutture che 
    il modo in cui queste vengono utilizzate. nota: in linux come P e V si utilizzano i comandi up e down. 

b) In un file system tipico di UNIX (ext2/3, bffs, etc) l'accesso diretto è meno efficiente quando il file è di grandi
dimensioni. E' vero o falso? Perché?

    In realtà è falso, in quanto UNIX utilizza una combinazione di due tecniche di accesso sfruttando gli inode.
    In particolare queste due tecniche vengono utilizzate per migliorare le performance di accesso, distinguendo tra file di grandi dimensioni
    (con accesso indiretto e indice multilivello) e insiemi sequenziali di dati (concatenazione di blocchi indice)   


c) Per risolvere una situazione di trashing di memoria occorre terminare forzatamente un processo. E' vero o falso?
Perché?

    Se la situazione è già in fase di trashing è necessario terminare almeno uno dei processi in esecuzione, altrimenti i 
    processi contiueranno a produrre più page fault che operazioni. In particolare utilizzando il working set siamo in grado di
    determinare il numero di pagine di cui ogni processo determina, riuscendo ad individuare quanti e quali devono essere stoppati per 
    consentire agli altri di operare minimizzando i page fault. 

d) Dato un sistema monoprocessore che elabora dati in modo batch, cosa cambia se si usa uno scheduler round-robin
al posto di uno FIFO? 

    L’elaborazione in batch consente di elaborare i job quando le risorse necessarie sono disponibili.
    Da questo cpossiamo dedurre che non saranno necessarie operazioni di I/O e i processi avranno un unico inseme di task da risolvere
    La differenza tra uno scheduler round robin e uno fifo si vede ne momento in cui il timeslice di RR è minore del tempo che serve 
    al completamento di almeno uno dei processi, poichè in tal caso il processo terminerà la sua esecuzione in seguito.
    Mentre considerando che la politica fifo è non preemptive, l'ordine di esecuzione dei processi è dato semplicemente dal loro tempo 
    di arrivo e duna volta che un processo ha iniziato la propria esecuzione, non lascerà il posto ad un altro finchè non avrà terminato.
    per quanto riguarda altre differenze tra i due algoritmi di scheduling, abbiamo che fifo è più semplice da implementare, ma:
    -possiede elevati tempi medi di attesa e di turnaround
    -spesso i processi CPU bound ritardano i processi I/O bound
    Round robin evita il manifestarsi del convoy effect fornendo a tutti i processi le stesse possibilità di esecuzione, c'è però da dire 
    che questa non è una nota interamente positiva, infatti c'è da considerare che non tutti i processi hanno la stesa importanza.
